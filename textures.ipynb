{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load images and resize them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from PIL import Image \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "\n",
    "def load_resize(images_path):\n",
    "    # return array of resized images\n",
    "    imagesList = listdir(images_path)\n",
    "    loadedResizedImages = []\n",
    "    for image in imagesList:\n",
    "        img = imread(images_path + image)\n",
    "        grayimg = rgb2gray(img)\n",
    "        resized_img = resize(grayimg,(32,32))\n",
    "        loadedResizedImages.append(resized_img)\n",
    "\n",
    "    return loadedResizedImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-2276c3d9f1e0>:15: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  grayimg = rgb2gray(img)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'canvas')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirs = ['canvas1','cushion1','linsseeds1','sand1','seat2','stone1']\n",
    "train = []\n",
    "for dir_ in dirs :\n",
    "    train.append(load_resize(\"textures\\\\training\"+\"\\\\\"+dir_+\"\\\\\"))\n",
    "train = [list for sublist in train for list in sublist]\n",
    "\n",
    "test = []\n",
    "for dir_ in dirs :\n",
    "    test.append(load_resize(\"textures\\\\testing\"+\"\\\\\"+dir_+\"\\\\\"))\n",
    "test = [list for sublist in test for list in sublist]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.subplot(121), imshow(train[0])\n",
    "plt.title('canvas') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainflatten_img = []\n",
    "for img in train:\n",
    "    trainflatten_img.append(list(img.flatten()))\n",
    "\n",
    "testflatten_img = []\n",
    "for img in test:\n",
    "    testflatten_img.append(list(img.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(trainflatten_img[0]))\n",
    "print(len(testflatten_img[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_fun(imageA,imageB,normalize):\n",
    "\n",
    "    if normalize == 'y':\n",
    "          cor = np.sum(np.multiply(np.array(imageA),np.array(imageB))) / np.sqrt(np.sum(np.square(np.array(imageA)))*np.sum(np.square(np.array(imageB))))\n",
    "    else:  \n",
    "          cor = np.sum(np.multiply(np.array(imageA),np.array(imageB)))\n",
    "            \n",
    "    return cor\n",
    "\n",
    "def conv_fun(imageA,imageB,normalize):\n",
    "    if normalize == 'y':\n",
    "        imageA = (imageA-np.mean(imageA))/(np.std(imageA))\n",
    "        imageB = (imageB-np.mean(imageB))/(np.std(imageB))\n",
    "        conv = np.sum(np.multiply(np.array(imageA),np.array(np.flipud(imageB))))\n",
    "    else:\n",
    "        conv = np.sum(np.multiply(np.array(imageA),np.array(np.flipud(imageB))))\n",
    "        \n",
    "    return conv\n",
    "\n",
    "def ssd_fun(imageA,imageB,normalize):\n",
    "    if normalize == 'y':\n",
    "        imageA = (imageA-np.mean(imageA))/(np.std(imageA))\n",
    "        imageB = (imageB-np.mean(imageB))/(np.std(imageB))\n",
    "        ssd = np.sum((np.array(imageA) - np.array(imageB))**2)\n",
    "    else:                  \n",
    "        ssd = np.sum((np.array(imageA) - np.array(imageB))**2)\n",
    "                       \n",
    "    return ssd\n",
    "\n",
    "def matchingImages( imageA, imageB, method, normalize='n'):\n",
    "    if method == 'cc' : \n",
    "        return cc_fun(imageA,imageB,normalize)\n",
    "    elif method == 'conv' :\n",
    "        return conv_fun(imageA,imageB,normalize)\n",
    "    elif method == 'ssd' : \n",
    "        return ssd_fun(imageA,imageB,normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.144514609765483\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "i = random.choice(range(len(trainflatten_img)))\n",
    "j = random.choice(range(len(trainflatten_img)))\n",
    "print(matchingImages(trainflatten_img[i],trainflatten_img[j],'ssd','n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pair images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations        \n",
    "import pandas as pd\n",
    "\n",
    "pairs = pd.DataFrame(columns=('imageA','imageB','Label'))\n",
    "counter=0      \n",
    "res = list(combinations(trainflatten_img, 2))\n",
    "for i in range(len(res)):\n",
    "    pairs.at[counter,'imageA']=res[i][0]\n",
    "    pairs.at[counter,'imageB']=res[i][1]\n",
    "    counter+=1\n",
    "\n",
    "test_pairs = pd.DataFrame(columns=('imageA','imageB','Label'))\n",
    "count=0  \n",
    "res_test = list(combinations(testflatten_img, 2))\n",
    "for i in range(len(res_test)):\n",
    "    test_pairs.at[count,'imageA']=res_test[i][0]\n",
    "    test_pairs.at[count,'imageB']=res_test[i][1]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageA</th>\n",
       "      <th>imageB</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.4, 0.4215686274509804, 0.43823529411764706,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.48725490196078425, 0.48627450980392156, 0.4...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5617647058823529, 0.5343137254901962, 0.456...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.45294117647058835, 0.4647058823529411, 0.47...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5196078431372548, 0.4784313725490196, 0.486...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              imageA  \\\n",
       "0  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "1  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "2  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "3  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "4  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "\n",
       "                                              imageB Label  \n",
       "0  [0.4, 0.4215686274509804, 0.43823529411764706,...   NaN  \n",
       "1  [0.48725490196078425, 0.48627450980392156, 0.4...   NaN  \n",
       "2  [0.5617647058823529, 0.5343137254901962, 0.456...   NaN  \n",
       "3  [0.45294117647058835, 0.4647058823529411, 0.47...   NaN  \n",
       "4  [0.5196078431372548, 0.4784313725490196, 0.486...   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train data & Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1=trainflatten_img[:30]\n",
    "class2=trainflatten_img[30:60]\n",
    "class3=trainflatten_img[60:90]\n",
    "class4=trainflatten_img[90:120]\n",
    "class5=trainflatten_img[120:150]\n",
    "class6=trainflatten_img[150:]\n",
    "\n",
    "# print(len(class1))\n",
    "# print(len(class2))\n",
    "# print(len(class3))\n",
    "# print(len(class4))\n",
    "# print(len(class5))\n",
    "# print(len(class6))\n",
    "\n",
    "truth = pairs.copy()\n",
    "for i in range(len(truth)):\n",
    "    if truth.imageA[i] in class1 and truth.imageB[i] in class1:\n",
    "        truth.loc[i,'Label']=1\n",
    "    elif truth.imageA[i] in class2 and truth.imageB[i] in class2:\n",
    "        truth.loc[i,'Label']=1\n",
    "    elif truth.imageA[i] in class3 and truth.imageB[i] in class3:\n",
    "        truth.loc[i,'Label']=1\n",
    "    elif truth.imageA[i] in class4 and truth.imageB[i] in class4:\n",
    "        truth.loc[i,'Label']=1\n",
    "    elif truth.imageA[i] in class5 and truth.imageB[i] in class5:\n",
    "        truth.loc[i,'Label']=1\n",
    "    elif truth.imageA[i] in class6 and truth.imageB[i] in class6:\n",
    "        truth.loc[i,'Label']=1\n",
    "    else: truth.loc[i,'Label']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageA</th>\n",
       "      <th>imageB</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.4, 0.4215686274509804, 0.43823529411764706,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.48725490196078425, 0.48627450980392156, 0.4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5617647058823529, 0.5343137254901962, 0.456...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.45294117647058835, 0.4647058823529411, 0.47...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5196078431372548, 0.4784313725490196, 0.486...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              imageA  \\\n",
       "0  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "1  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "2  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "3  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "4  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "\n",
       "                                              imageB Label  \n",
       "0  [0.4, 0.4215686274509804, 0.43823529411764706,...     1  \n",
       "1  [0.48725490196078425, 0.48627450980392156, 0.4...     1  \n",
       "2  [0.5617647058823529, 0.5343137254901962, 0.456...     1  \n",
       "3  [0.45294117647058835, 0.4647058823529411, 0.47...     1  \n",
       "4  [0.5196078431372548, 0.4784313725490196, 0.486...     1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([13500.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,  2610.]),\n",
       " array([0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001,\n",
       "        0.7000000000000001, 0.8, 0.9, 1.0], dtype=object),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "plt.hist(truth['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1=testflatten_img[:10]\n",
    "class2=testflatten_img[10:20]\n",
    "class3=testflatten_img[20:30]\n",
    "class4=testflatten_img[30:40]\n",
    "class5=testflatten_img[40:50]\n",
    "class6=testflatten_img[50:]\n",
    "\n",
    "# print(len(class1))\n",
    "# print(len(class2))\n",
    "# print(len(class3))\n",
    "# print(len(class4))\n",
    "# print(len(class5))\n",
    "# print(len(class6))\n",
    "\n",
    "testing = test_pairs.copy()\n",
    "for i in range(len(testing)):\n",
    "    if testing.imageA[i] in class1 and testing.imageB[i] in class1:\n",
    "        testing.loc[i,'Label']=1\n",
    "    elif testing.imageA[i] in class2 and testing.imageB[i] in class2:\n",
    "        testing.loc[i,'Label']=1\n",
    "    elif testing.imageA[i] in class3 and testing.imageB[i] in class3:\n",
    "        testing.loc[i,'Label']=1\n",
    "    elif testing.imageA[i] in class4 and testing.imageB[i] in class4:\n",
    "        testing.loc[i,'Label']=1\n",
    "    elif testing.imageA[i] in class5 and testing.imageB[i] in class5:\n",
    "        testing.loc[i,'Label']=1\n",
    "    elif testing.imageA[i] in class6 and testing.imageB[i] in class6:\n",
    "        testing.loc[i,'Label']=1\n",
    "    else: testing.loc[i,'Label']=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier data using match images function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cor_n=[]\n",
    "t_cor=[]\n",
    "t_conv_n=[]\n",
    "t_conv=[]\n",
    "t_ssd_n=[]\n",
    "t_ssd=[]\n",
    "for i in range(len(pairs)):  \n",
    "        t_cor_n.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'cc','y'))\n",
    "        t_cor.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'cc','n'))\n",
    "        t_conv_n.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'conv','y'))\n",
    "        t_conv.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'conv','n'))\n",
    "        t_ssd_n.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'ssd','y'))\n",
    "        t_ssd.append(matchingImages(pairs.imageA[i],pairs.imageB[i],'ssd','n'))\n",
    "Tcor_n = sum(t_cor_n)/len(t_cor_n)\n",
    "Tcor = sum(t_cor)/len(t_cor)\n",
    "Tconv_n = sum(t_conv_n)/len(t_conv_n)\n",
    "Tconv = sum(t_conv)/len(t_conv)\n",
    "Tssd_n = sum(t_ssd_n)/len(t_ssd_n)\n",
    "Tssd = sum(t_ssd)/len(t_ssd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tcor_n 0.9853362502604934\n",
      "Tcor 249.98652284276508\n",
      "Tconv_n -5.030632242754579\n",
      "Tconv 249.96776050388772\n",
      "Tssd_n 2031.9820963827817\n",
      "Tssd 7.466723324255023\n"
     ]
    }
   ],
   "source": [
    "print('Tcor_n',Tcor_n)\n",
    "print('Tcor',Tcor)\n",
    "print('Tconv_n',Tconv_n)\n",
    "print('Tconv',Tconv)\n",
    "print('Tssd_n',Tssd_n)\n",
    "print('Tssd',Tssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pairs.copy()\n",
    "for i in range(len(classifier)):\n",
    "    t = matchingImages(classifier.imageA[i],classifier.imageB[i],'ssd','n')\n",
    "    if Tssd >= t:\n",
    "        classifier.loc[i,'Label']=1\n",
    "    else:\n",
    "        classifier.loc[i,'Label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageA</th>\n",
       "      <th>imageB</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.4, 0.4215686274509804, 0.43823529411764706,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.48725490196078425, 0.48627450980392156, 0.4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5617647058823529, 0.5343137254901962, 0.456...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.45294117647058835, 0.4647058823529411, 0.47...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.4960784313725489, 0.5019607843137255, 0.452...</td>\n",
       "      <td>[0.5196078431372548, 0.4784313725490196, 0.486...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              imageA  \\\n",
       "0  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "1  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "2  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "3  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "4  [0.4960784313725489, 0.5019607843137255, 0.452...   \n",
       "\n",
       "                                              imageB Label  \n",
       "0  [0.4, 0.4215686274509804, 0.43823529411764706,...     1  \n",
       "1  [0.48725490196078425, 0.48627450980392156, 0.4...     1  \n",
       "2  [0.5617647058823529, 0.5343137254901962, 0.456...     1  \n",
       "3  [0.45294117647058835, 0.4647058823529411, 0.47...     1  \n",
       "4  [0.5196078431372548, 0.4784313725490196, 0.486...     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8018.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        8092.]),\n",
       " array([0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001,\n",
       "        0.7000000000000001, 0.8, 0.9, 1.0], dtype=object),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "plt.hist(classifier['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate classification data using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tru = truth.loc[:4110]\n",
    "val_clas = classifier.loc[:4110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.39      3686\n",
      "           1       0.13      1.00      0.23       425\n",
      "\n",
      "    accuracy                           0.32      4111\n",
      "   macro avg       0.57      0.62      0.31      4111\n",
      "weighted avg       0.91      0.32      0.37      4111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(val_tru['Label'].astype(int), val_clas['Label'].astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 886, 2800],\n",
       "       [   0,  425]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(val_tru['Label'].astype(int), val_clas['Label'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validate classification data using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier = test_pairs.copy()\n",
    "for i in range(len(test_classifier)):\n",
    "    t = matchingImages(test_classifier.imageA[i],test_classifier.imageB[i],'ssd','n')\n",
    "    if Tssd >= t:\n",
    "        test_classifier.loc[i,'Label']=1\n",
    "    else:\n",
    "        test_classifier.loc[i,'Label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.55      0.66      1500\n",
      "           1       0.15      0.46      0.23       270\n",
      "\n",
      "    accuracy                           0.53      1770\n",
      "   macro avg       0.50      0.50      0.45      1770\n",
      "weighted avg       0.74      0.53      0.60      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(testing['Label'].astype(int), test_classifier['Label'].astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = []\n",
    "#concatenate images\n",
    "for i in range(len(truth)):\n",
    "    li = truth.imageA[i].copy()\n",
    "    for j in truth.imageB[i] : \n",
    "        li.append(j) \n",
    "    Train.append(li)\n",
    "#np.array(train).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## before sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = (truth['Label'].loc[4110:]).astype(int)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(train[4110:]), y, stratify=y,random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(np.array(Train[4110:]), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.44      0.58      3686\n",
      "           1       0.07      0.34      0.11       425\n",
      "\n",
      "    accuracy                           0.43      4111\n",
      "   macro avg       0.46      0.39      0.34      4111\n",
      "weighted avg       0.77      0.43      0.53      4111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "#concatenate images\n",
    "for i in range(len(val_tru)):\n",
    "    li = val_tru.imageA[i].copy()\n",
    "    for j in val_tru.imageB[i] : \n",
    "        li.append(j) \n",
    "    val.append(li)\n",
    "y_pred = clf.predict(np.array(val))\n",
    "print(classification_report(val_tru['Label'].astype(int), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = (truth['Label']).astype(int)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(train[4110:]), y, stratify=y,random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(np.array(Train), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.32      0.47      1500\n",
      "           1       0.17      0.76      0.28       270\n",
      "\n",
      "    accuracy                           0.39      1770\n",
      "   macro avg       0.52      0.54      0.37      1770\n",
      "weighted avg       0.77      0.39      0.44      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = []\n",
    "#concatenate images\n",
    "for i in range(len(testing)):\n",
    "    li = testing.imageA[i].copy()\n",
    "    for j in testing.imageB[i] : \n",
    "        li.append(j) \n",
    "    t.append(li)\n",
    "y_pred = clf.predict(np.array(t))\n",
    "print(classification_report(testing['Label'].astype(int), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_res, y_res = rus.fit_resample(np.array(Train[4110:]), (truth['Label'].loc[4110:]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2185.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        2185.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.23      0.36      3686\n",
      "           1       0.10      0.75      0.18       425\n",
      "\n",
      "    accuracy                           0.28      4111\n",
      "   macro avg       0.49      0.49      0.27      4111\n",
      "weighted avg       0.81      0.28      0.34      4111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\potato\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# X_train_, X_test_, y_train_, y_test_ = train_test_split(X_res, y_res, stratify=y_res,random_state=42)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_res, y_res)\n",
    "y_pred = clf.predict(np.array(val))\n",
    "print(classification_report(val_tru['Label'].astype(int), y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_res, y_res = rus.fit_resample(np.array(Train), (truth['Label']).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.41      0.55      1500\n",
      "           1       0.16      0.63      0.26       270\n",
      "\n",
      "    accuracy                           0.44      1770\n",
      "   macro avg       0.51      0.52      0.41      1770\n",
      "weighted avg       0.75      0.44      0.51      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "# X_train_, X_test_, y_train_, y_test_ = train_test_split(X_res, y_res, stratify=y_res,random_state=42)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_res, y_res)\n",
    "y_pred = clf.predict(t)\n",
    "print(classification_report(testing['Label'].astype(int), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy of classifier according to a subset of data (validation data) with ssd as a matching method = 32%\n",
    "- The accuracy of classifier according to testing data = 53%\n",
    "- The accuracy of MLP model according to validation data before under sampling = 43%\n",
    "- The accuracy of MLP model according to testing data before under sampling =  39%\n",
    "- The accuracy of MLP model according to validation data after under sampling = 28%\n",
    "- The accuracy of MLP model according to testing data after under sampling = 44%\n",
    "\n",
    "From these accuracies we can say that the best is classifier model, that model predict better than the MLP before and after under sampling. Also under sampling make the model better may be beacuse the under sampling decrease the data so the model learn accuratly. and before under sampling the accuracy of MLP was worst than the classifier may be beacuse the data in MLP was unbalanced but in classifier the data was balanced.\n",
    "\n",
    "The classifier model needed much effort than the MLP model because MLP was a builtin algorithm in sklearn in the oppesit of classifier model which needed many loops and many steps to get the treshold to classify the data.but the both of them weren't took much time to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering an Filtring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def features(imgs,bin=32):\n",
    "    li = []\n",
    "    for i in np.array(imgs):\n",
    "        f, edges= np.histogram(i,bins=bin)\n",
    "        li.append(f)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = features(Train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = features(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = (truth['Label'].loc[4110:]).astype(int)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(train[4110:]), y, stratify=y,random_state=1)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(np.array(Train[4110:]), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88      3686\n",
      "           1       0.29      0.67      0.40       425\n",
      "\n",
      "    accuracy                           0.79      4111\n",
      "   macro avg       0.62      0.74      0.64      4111\n",
      "weighted avg       0.89      0.79      0.83      4111\n",
      "\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "4106    0\n",
      "4107    0\n",
      "4108    0\n",
      "4109    0\n",
      "4110    0\n",
      "Name: Label, Length: 4111, dtype: object\n"
     ]
    }
   ],
   "source": [
    "val = []\n",
    "val_tru = truth.loc[:4110]\n",
    "#concatenate images\n",
    "for i in range(len(val_tru)):\n",
    "    li = val_tru.imageA[i].copy()\n",
    "    for j in val_tru.imageB[i] : \n",
    "        li.append(j) \n",
    "    val.append(li)\n",
    "val = features(val)   \n",
    "y_pred = clf.predict(np.array(val))\n",
    "print(classification_report(val_tru['Label'].astype(int), y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = (truth['Label']).astype(int)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(np.array(train[4110:]), y, stratify=y,random_state=1)\n",
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(np.array(Train), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      1500\n",
      "           1       0.60      0.58      0.59       270\n",
      "\n",
      "    accuracy                           0.88      1770\n",
      "   macro avg       0.76      0.75      0.76      1770\n",
      "weighted avg       0.88      0.88      0.88      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(np.array(Test))\n",
    "print(classification_report(testing['Label'].astype(int), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the filtring increase the accuracy of the model because it get more features to train on it and learned more.Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models, resulting in improved model accuracy on unseen data.The accuracy become 88% which is better than the last 2 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
